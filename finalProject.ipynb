{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPy7ugNn8tlMW4Ty7fV7erf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirshed/FlightGear-WPF/blob/master/finalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp_cN-0aQAkk",
        "outputId": "43e7f715-17a5-44eb-e3ff-f8c05f800ef3"
      },
      "source": [
        "# MOUNTING TO DRIVE AND CD INTO FOLDER\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the code and datasets.\n",
        "# Recommended path: 'deep_perception/assignments/assignment1/'\n",
        "FOLDERNAME = 'deep_perception/assignments/final_project'\n",
        "ASSIGNMENTNAME = 'final_project'\n",
        "os.chdir(f\"drive/MyDrive/{FOLDERNAME}\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/deep_perception/assignments/final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-KQ8WfQfjc-",
        "outputId": "19e671e5-2c85-4822-f1d8-1897fa24e310"
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/deep_perception/assignments/final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfrToA_Citbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb89619e-71a9-4cc1-8938-5047544d089f"
      },
      "source": [
        "# !python main.py\n",
        "!python main.py --resume --lr=0.01"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "==> Resuming from checkpoint..\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 81, in <module>\n",
            "    net.load_state_dict(checkpoint['net'])\n",
            "KeyError: 'net'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B_Z-1A-_RNP"
      },
      "source": [
        "# retrieving saved net from drive\n",
        "from vgg import *\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "net = VGG('VGG19')\n",
        "device = 'cuda'\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "net.load_state_dict(checkpoint['net'])\n",
        "best_acc = checkpoint['acc']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMYmKmDjHVp8"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv6GNYnmcgL7"
      },
      "source": [
        "# new gradcam class\n",
        "class GradCamVGG(nn.Module):\n",
        "    def __init__(self, net):\n",
        "        super(GradCamVGG, self).__init__()\n",
        "\n",
        "        self.vgg_model = net\n",
        "        # cut the network and get the feture extractor: \n",
        "        #   all layers from the beginning to the last conv layer\n",
        "        self.features_until_last_conv = self.vgg_model.module.features[:52] # layers [0 to 52) (excluding 52)\n",
        "        # self.features_until_last_conv = self.vgg_model[:52]\n",
        "        # create a new max pooling that links between features and classifier\n",
        "        self.max_pool_layer = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "        # get the classifier\n",
        "        self.classifier = self.vgg_model.module.classifier\n",
        "    \n",
        "    def capture_gradients(self, grad):\n",
        "        # hook for the gradients of the activations\n",
        "        self.features_gradients = grad\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        # extract features of kast conv layer\n",
        "        return self.features_until_last_conv(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pass image trough the first part of the network to extract features\n",
        "        x = self.extract_features(x)\n",
        "\n",
        "        # hook the features tensor to extract features during backprop\n",
        "        h = x.register_hook(self.capture_gradients)\n",
        "\n",
        "        # forward through the rest of the network (max_pool_layer and classifier)\n",
        "        x = self.max_pool_layer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_1X_YzCJoB0",
        "outputId": "5bbde256-fbfe-4b8a-ca83-5a48039b52b7"
      },
      "source": [
        "# creating data loaders\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=1, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDNSBFCGZ1l5"
      },
      "source": [
        "def gradients_global_avg_polling(gradients):\n",
        "  return torch.nn.AvgPool3d((1, gradients.shape[2], gradients.shape[3]))(gradients)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcAFJRu0Z2Hz"
      },
      "source": [
        "# creating heatmap\n",
        "def grad_cam_heatmap(activations, alpha_values):\n",
        "  activations = activations.clone()\n",
        "  # activations = activations.reshape(1,1,1,-1)\n",
        "  activations = torch.mul(activations, alpha_values)\n",
        "  # create a heatmap by average the channels of the activations\n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "  # apply relu and normalize the heatmap\n",
        "  heatmap = F.relu(heatmap)\n",
        "  heatmap /= torch.max(heatmap)\n",
        "  return heatmap"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxtANl9oaoqT"
      },
      "source": [
        "# combining original image with heatmap\n",
        "def get_image_with_heatmap(img, heatmap):\n",
        "  # img = cv2.imread(content_image_path)\n",
        "  # print(img.shape)\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  superimposed_img = heatmap * 0.4 + img\n",
        "  return superimposed_img"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI7iQeui3Ebh"
      },
      "source": [
        "# plotting combined image\n",
        "def plot_superimposed_img(superimposed_img):\n",
        "  # cv2_imshow(superimposed_img)\n",
        "  plt.imshow(superimposed_img)\n",
        "  plt.pause(0.001)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oXSOqq5cgvp"
      },
      "source": [
        "# interating over 5000 images and transforming them to new data (img+heatmap)\n",
        "# saving new data and labels\n",
        "from IPython.display import clear_output \n",
        "# creat an instance of our vgg model\n",
        "vgg_grad_cam = GradCamVGG(net).cuda()\n",
        "\n",
        "# set model in eval mode (alternative to freezing)\n",
        "vgg_grad_cam.eval()\n",
        "\n",
        "labels = []\n",
        "for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "  if (batch_idx == 5000):\n",
        "    break\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "  predictions = vgg_grad_cam(inputs)\n",
        "  activations = vgg_grad_cam.extract_features(inputs)\n",
        "  predictions[:, predictions.argmax(1)].backward()\n",
        "  gradients = vgg_grad_cam.features_gradients\n",
        "  # print(\"Last layer features shape:\", activations.shape)\n",
        "  # print(\"Last layer gradients shape:\", gradients.shape)\n",
        "  alpha_values = gradients_global_avg_polling(gradients)\n",
        "  # print(\"Alpha values shape:\", alpha_values.shape)\n",
        "  # calculate heatmap\n",
        "  heatmap = grad_cam_heatmap(activations, alpha_values).detach().cpu().numpy()\n",
        "  # print heatmap shape\n",
        "  # print(\"Heatmap Shape:\", heatmap.shape)\n",
        "  img = np.transpose(inputs[0].cpu().detach().numpy(), (1, 2, 0))\n",
        "  heatmap_img = get_image_with_heatmap(img, heatmap)\n",
        "  # plt.imshow(img)\n",
        "  # plt.pause(0.001)\n",
        "  plt.imshow(heatmap_img)\n",
        "  plt.gca().set_axis_off()\n",
        "  plt.savefig(f\"./heatmap_imgs/{batch_idx}\", bbox_inches='tight',transparent=True, pad_inches=0)\n",
        "  labels.append(targets)\n",
        "  plt.pause(0.001)\n",
        "  clear_output()"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjkjD5kBEML9"
      },
      "source": [
        "# saving labels to drive\n",
        "with open(\"./labels.txt\", 'w+') as f:\n",
        "  for lab in labels:\n",
        "    f.write(\"%s\\n\" % lab.cpu().numpy()[0])"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQr0SEgOY8f3"
      },
      "source": [
        "# functions for convert image to tensor for running net on changed images\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "def image_to_tensor(image_numpy, max_size=400, shape=None):\n",
        "  \n",
        "  # crop image if image is too big\n",
        "  if max(image_numpy.size) > max_size:\n",
        "    size = max_size\n",
        "  else:\n",
        "    size = max(image_numpy.size)\n",
        "\t\n",
        "  size = (size, int(1.5*size))\n",
        "  # if shape is given use it\n",
        "  if shape is not None:\n",
        "    size = shape\n",
        "  \n",
        "  # resize and normalize the image\n",
        "  in_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "  ])\n",
        "  \n",
        "  image = in_transform(image_numpy)[:3, :, :].unsqueeze(0)\n",
        "  \n",
        "  return image\n",
        "\n",
        "def image_path_to_numpy(image_path):\n",
        "  # load image into a numpy array from the given path\n",
        "  return Image.open(image_path).convert('RGB') "
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prFx-U8khtDn"
      },
      "source": [
        "# dataset class for img_heatmap datatype\n",
        "class HeatDataset(torch.utils.data.Dataset):\n",
        "  # 'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels):\n",
        "        # 'Initialization'\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "        # 'Denotes the total number of samples'\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # 'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = self.list_IDs[index]\n",
        "\n",
        "        # Load data and get label\n",
        "        # X = torch.load('data/' + ID + '.pt')\n",
        "        X = image_path_to_numpy(f\"./heatmap_imgs/{ID}.png\")\n",
        "        X = image_to_tensor(X)\n",
        "        y = self.labels[index]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "# loader examples\n",
        "train_ids = list(range(0, 4000))\n",
        "with open(\"./labels.txt\", 'r') as f:\n",
        "  labels = f.read().split('\\n')\n",
        "labels = labels[:-1]\n",
        "# casting labels to ints \n",
        "for i in range(0, len(labels)):\n",
        "    labels[i] = int(labels[i])\n",
        "\n",
        "train_labs = labels[:4000]\n",
        "test_ids = list(range(4000,5000))\n",
        "test_labs = labels[4000:]\n",
        "\n",
        "trainset = HeatDataset(train_ids, train_labs)\n",
        "testset = HeatDataset(test_ids, test_labs)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyXSeFz7hxUL",
        "outputId": "a5930411-16e5-4366-9df6-46b04d133c4a"
      },
      "source": [
        "print(len(test_labs))\n",
        "print(len(test_ids))"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JZP9fV1Sy6z",
        "outputId": "3453445d-2911-4efb-ecf4-2f55d5969268"
      },
      "source": [
        "# running the model on new data\n",
        "# note that some of the code written in colab is written in new_main.py as well\n",
        "!python new_main.py"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.589 | Acc: 9.300% (372/4000) 4000/4000 \n",
            " [================================================================>]  Step: 11ms | Tot: 10s295ms | Loss: 5.292 | Acc: 13.700% (137/1000) 1000/1000 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.329 | Acc: 9.425% (377/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s432ms | Loss: 6.313 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.327 | Acc: 9.725% (389/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s612ms | Loss: 9.386 | Acc: 11.700% (117/1000) 1000/1000 \n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.326 | Acc: 9.950% (398/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s762ms | Loss: 3.379 | Acc: 11.600% (116/1000) 1000/1000 \n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.322 | Acc: 10.975% (439/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s286ms | Loss: 4.241 | Acc: 10.800% (108/1000) 1000/1000 \n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 26ms | Tot: 1m59s | Loss: 2.326 | Acc: 9.725% (389/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s406ms | Loss: 4.433 | Acc: 11.000% (110/1000) 1000/1000 \n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.325 | Acc: 10.100% (404/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s806ms | Loss: 2.790 | Acc: 11.000% (110/1000) 1000/1000 \n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 32ms | Tot: 2m1s | Loss: 2.325 | Acc: 10.025% (401/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s934ms | Loss: 2.516 | Acc: 8.800% (88/1000) 1000/1000 \n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 27ms | Tot: 2m766ms | Loss: 2.325 | Acc: 10.225% (409/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s430ms | Loss: 2.376 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.325 | Acc: 9.700% (388/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s530ms | Loss: 2.338 | Acc: 10.000% (100/1000) 1000/1000 \n",
            "\n",
            "Epoch: 10\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.328 | Acc: 9.475% (379/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s626ms | Loss: 2.421 | Acc: 9.100% (91/1000) 1000/1000 \n",
            "\n",
            "Epoch: 11\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.328 | Acc: 10.250% (410/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 11s68ms | Loss: 2.328 | Acc: 9.700% (97/1000) 1000/1000 \n",
            "\n",
            "Epoch: 12\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.324 | Acc: 10.775% (431/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s813ms | Loss: 2.312 | Acc: 10.100% (101/1000) 1000/1000 \n",
            "\n",
            "Epoch: 13\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.327 | Acc: 10.450% (418/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s786ms | Loss: 2.316 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 14\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.327 | Acc: 10.300% (412/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s684ms | Loss: 2.320 | Acc: 11.600% (116/1000) 1000/1000 \n",
            "\n",
            "Epoch: 15\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.327 | Acc: 10.325% (413/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s933ms | Loss: 2.322 | Acc: 10.200% (102/1000) 1000/1000 \n",
            "\n",
            "Epoch: 16\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.324 | Acc: 10.800% (432/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s746ms | Loss: 2.342 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 17\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.326 | Acc: 9.975% (399/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s64ms | Loss: 2.344 | Acc: 8.900% (89/1000) 1000/1000 \n",
            "\n",
            "Epoch: 18\n",
            " [================================================================>]  Step: 28ms | Tot: 2m2s | Loss: 2.323 | Acc: 10.900% (436/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s588ms | Loss: 2.323 | Acc: 10.700% (107/1000) 1000/1000 \n",
            "\n",
            "Epoch: 19\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.322 | Acc: 10.450% (418/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s49ms | Loss: 2.311 | Acc: 11.000% (110/1000) 1000/1000 \n",
            "\n",
            "Epoch: 20\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.327 | Acc: 9.050% (362/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s765ms | Loss: 2.326 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 21\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.325 | Acc: 10.050% (402/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s532ms | Loss: 2.315 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 22\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.327 | Acc: 9.575% (383/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s815ms | Loss: 2.312 | Acc: 10.700% (107/1000) 1000/1000 \n",
            "\n",
            "Epoch: 23\n",
            " [================================================================>]  Step: 26ms | Tot: 2m2s | Loss: 2.327 | Acc: 9.675% (387/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s355ms | Loss: 2.327 | Acc: 8.500% (85/1000) 1000/1000 \n",
            "\n",
            "Epoch: 24\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.322 | Acc: 10.150% (406/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s685ms | Loss: 2.345 | Acc: 10.400% (104/1000) 1000/1000 \n",
            "\n",
            "Epoch: 25\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.324 | Acc: 9.575% (383/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s552ms | Loss: 2.318 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 26\n",
            " [================================================================>]  Step: 29ms | Tot: 2m1s | Loss: 2.328 | Acc: 10.125% (405/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s929ms | Loss: 2.336 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 27\n",
            " [================================================================>]  Step: 28ms | Tot: 2m3s | Loss: 2.325 | Acc: 9.550% (382/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 11s31ms | Loss: 2.320 | Acc: 9.500% (95/1000) 1000/1000 \n",
            "\n",
            "Epoch: 28\n",
            " [================================================================>]  Step: 26ms | Tot: 2m821ms | Loss: 2.325 | Acc: 9.550% (382/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s587ms | Loss: 2.321 | Acc: 8.500% (85/1000) 1000/1000 \n",
            "\n",
            "Epoch: 29\n",
            " [================================================================>]  Step: 28ms | Tot: 2m618ms | Loss: 2.324 | Acc: 10.250% (410/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s530ms | Loss: 2.308 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 30\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.324 | Acc: 9.400% (376/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s453ms | Loss: 2.325 | Acc: 8.500% (85/1000) 1000/1000 \n",
            "\n",
            "Epoch: 31\n",
            " [================================================================>]  Step: 28ms | Tot: 2m2s | Loss: 2.324 | Acc: 9.575% (383/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s229ms | Loss: 2.308 | Acc: 10.400% (104/1000) 1000/1000 \n",
            "\n",
            "Epoch: 32\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.327 | Acc: 9.250% (370/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s650ms | Loss: 2.308 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 33\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.321 | Acc: 10.025% (401/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s557ms | Loss: 2.325 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 34\n",
            " [================================================================>]  Step: 28ms | Tot: 2m3s | Loss: 2.324 | Acc: 10.200% (408/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s59ms | Loss: 2.308 | Acc: 9.500% (95/1000) 1000/1000 \n",
            "\n",
            "Epoch: 35\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.324 | Acc: 9.650% (386/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s810ms | Loss: 2.309 | Acc: 8.500% (85/1000) 1000/1000 \n",
            "\n",
            "Epoch: 36\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.322 | Acc: 9.925% (397/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s608ms | Loss: 2.312 | Acc: 10.700% (107/1000) 1000/1000 \n",
            "\n",
            "Epoch: 37\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.325 | Acc: 8.625% (345/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s845ms | Loss: 2.314 | Acc: 10.100% (101/1000) 1000/1000 \n",
            "\n",
            "Epoch: 38\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.321 | Acc: 9.925% (397/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s474ms | Loss: 2.346 | Acc: 10.100% (101/1000) 1000/1000 \n",
            "\n",
            "Epoch: 39\n",
            " [================================================================>]  Step: 27ms | Tot: 2m2s | Loss: 2.324 | Acc: 9.525% (381/4000) 4000/4000 \n",
            " [================================================================>]  Step: 13ms | Tot: 10s831ms | Loss: 2.338 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 40\n",
            " [================================================================>]  Step: 28ms | Tot: 2m4s | Loss: 2.323 | Acc: 9.700% (388/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s9ms | Loss: 2.319 | Acc: 8.900% (89/1000) 1000/1000 \n",
            "\n",
            "Epoch: 41\n",
            " [================================================================>]  Step: 28ms | Tot: 2m4s | Loss: 2.322 | Acc: 10.625% (425/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 11s36ms | Loss: 2.320 | Acc: 10.100% (101/1000) 1000/1000 \n",
            "\n",
            "Epoch: 42\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.321 | Acc: 9.600% (384/4000) 4000/4000 \n",
            " [================================================================>]  Step: 9ms | Tot: 10s980ms | Loss: 2.318 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 43\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.326 | Acc: 9.750% (390/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s612ms | Loss: 2.313 | Acc: 10.200% (102/1000) 1000/1000 \n",
            "\n",
            "Epoch: 44\n",
            " [================================================================>]  Step: 27ms | Tot: 2m3s | Loss: 2.320 | Acc: 10.575% (423/4000) 4000/4000 \n",
            " [================================================================>]  Step: 16ms | Tot: 10s612ms | Loss: 2.333 | Acc: 10.900% (109/1000) 1000/1000 \n",
            "\n",
            "Epoch: 45\n",
            " [================================================================>]  Step: 27ms | Tot: 2m1s | Loss: 2.324 | Acc: 9.400% (376/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s635ms | Loss: 2.358 | Acc: 8.500% (85/1000) 1000/1000 \n",
            "\n",
            "Epoch: 46\n",
            " [================================================================>]  Step: 27ms | Tot: 2m939ms | Loss: 2.324 | Acc: 10.175% (407/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s234ms | Loss: 2.317 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 47\n",
            " [================================================================>]  Step: 28ms | Tot: 2m956ms | Loss: 2.323 | Acc: 9.350% (374/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s640ms | Loss: 2.326 | Acc: 8.900% (89/1000) 1000/1000 \n",
            "\n",
            "Epoch: 48\n",
            " [================================================================>]  Step: 26ms | Tot: 1m58s | Loss: 2.322 | Acc: 10.150% (406/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s634ms | Loss: 2.347 | Acc: 9.800% (98/1000) 1000/1000 \n",
            "\n",
            "Epoch: 49\n",
            " [================================================================>]  Step: 26ms | Tot: 1m58s | Loss: 2.322 | Acc: 10.150% (406/4000) 4000/4000 \n",
            " [================================================================>]  Step: 8ms | Tot: 10s447ms | Loss: 2.321 | Acc: 10.900% (109/1000) 1000/1000 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}